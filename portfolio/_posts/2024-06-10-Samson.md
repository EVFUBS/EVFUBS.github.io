---
layout: post
title:  "Samson"
categories: projects
---
Samson is a voice assistant I'm currently writing using .NET and new ML.NET features. It consists of a client project, a server that all the clients connect with and serves the models for the clients to use for predictions and a SQL Server DB that stores users and authorisation tokens.

## Client
The client is what the user interacts with it records small snippets of audio and sends that to wake model on the server. If the model returns with true the Wake Word is detected and the processing for listening continues, 

The Client is broken into 2 execution states
- listening 
- executing

while the client is listening it stays in sleep mode taking small snippets of audio when it detects audio and sending them to the server to process using the Wake model to see if it should continue listening otherwise it throws away the audio data.

Otherwise it'll continue to capture audio data once listening is finished it sends that data over to the server and uses the Action model to determine which execution action it needs to take by returning the predicted samson action, this is send back to the client and falls into the execution state

when executing it'll looks through all registered actions until it finds the corresponding action in the execution state and will execute any code defined under that action.

## Server
The server is used a monolith for the clients to interact with the model, authenticate their client and use the speech to text integration built into samson using the deepgram API and the text to speech integration using Google tts.

It serves the following 3 models
- Wake Model
    - Binary Classification Model, determines whether speech consists of the "Wake" word or not using mel spectograms
- Action Model
    - Multi Classification Model, determines which action the text that is used as an input is suggesting i.e "play a song on spotify" would return back as SpotifyPlayOrResumePlayback
- ActionNER Model (Yet to be implemented)
    - A named entity recognition model used to extract key information from the text send to the action model

## Models
Samson currently consists of the following 3 models
- Wake Model
    - Binary Classification Model, determines whether speech consists of the "Wake" word or not using mel spectograms
- Action Model
    - Multi Classification Model, determines which action the text that is used as an input is suggesting i.e "play a song on spotify" would return back as SpotifyPlayOrResumePlayback
- ActionNER Model (Yet to be implemented)
    - A named entity recognition model used to extract key information from the text send to the action model